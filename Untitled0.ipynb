{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOanXVddTCyEmByD41hPj+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardoLuca/AskYou/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "KZFMCJ_yKkTZ"
      },
      "outputs": [],
      "source": [
        "# Célula 1: Instalar as bibliotecas necessárias\n",
        "!pip install -q langchain langchain-google-genai datasets qdrant-client tiktoken\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2: Importar bibliotecas e configurar a API Key do Google\n",
        "import os\n",
        "import sys\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Variável para verificar se a configuração foi bem sucedida\n",
        "google_api_key_configurada = False\n",
        "chat = None # Inicializa a variável chat\n",
        "\n",
        "try:\n",
        "    # Pega a chave de API dos Secrets do Colab\n",
        "    # Certifique-se que o nome do secret é 'GOOGLE_API_KEY'\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    # Verifica se a chave foi realmente obtida (não é None ou vazia)\n",
        "    if not GOOGLE_API_KEY:\n",
        "        print(\"Erro: A chave de API 'GOOGLE_API_KEY' foi encontrada nos Secrets, mas está vazia.\", file=sys.stderr)\n",
        "    else:\n",
        "        print(\"Chave de API do Google carregada com sucesso!\")\n",
        "        google_api_key_configurada = True\n",
        "\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Erro: Secret 'GOOGLE_API_KEY' não encontrado.\", file=sys.stderr)\n",
        "    print(\"Por favor, adicione sua chave de API do Google AI Studio aos Secrets do Colab.\", file=sys.stderr)\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro inesperado ao buscar a chave de API: {e}\", file=sys.stderr)\n",
        "\n",
        "# Limpa a variável do ambiente se ela existir por algum motivo (boa prática)\n",
        "# Embora estejamos passando diretamente, é bom garantir que não haja conflito.\n",
        "if 'GOOGLE_API_KEY' in os.environ:\n",
        "    del os.environ['GOOGLE_API_KEY']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06Lg-QRmL67q",
        "outputId": "c4fe39ea-9d99-4f1a-e25a-bce22717d3a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chave de API do Google carregada com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3: Instanciar o modelo Gemini (só executa se a chave foi carregada)\n",
        "\n",
        "if google_api_key_configurada:\n",
        "    try:\n",
        "        # Escolha o modelo Gemini (ex: 'gemini-1.5-pro-latest', 'gemini-1.5-flash-latest')\n",
        "        chat = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-pro-latest\",  # Ou outro modelo Gemini compatível\n",
        "            google_api_key=GOOGLE_API_KEY,\n",
        "            # convert_system_message_to_human=True # Descomente se tiver problemas com SystemMessage\n",
        "                                                 # Isso faz com que a mensagem do sistema seja anexada\n",
        "                                                 # à primeira mensagem humana, o que às vezes funciona melhor com Gemini.\n",
        "        )\n",
        "        print(f\"Modelo {chat.model} instanciado com sucesso.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao instanciar o modelo ChatGoogleGenerativeAI: {e}\", file=sys.stderr)\n",
        "        chat = None # Garante que chat é None se a instanciação falhar\n",
        "else:\n",
        "    print(\"\\nInstanciação do modelo pulada pois a chave de API não foi configurada.\", file=sys.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_sy9Z4FNLwn",
        "outputId": "bae228b5-ea3b-402a-d639-e59b71f3fa0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo models/gemini-1.5-pro-latest instanciado com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4: Definir as mensagens (geralmente sem alterações)\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Você é um assistente útil que responde perguntas.\"),\n",
        "    HumanMessage(content=\"Olá Bot, como você está hoje?\"),\n",
        "    AIMessage(content=\"Estou bem, obrigado por perguntar! Como posso ajudar?\"),\n",
        "    HumanMessage(content=\"Gostaria de entender o que é Machine Learning\")\n",
        "]\n",
        "\n",
        "print(\"Lista de mensagens definida.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ6-pvMpMS-H",
        "outputId": "466148be-c3ca-42b7-ba1c-8ad00128e8ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lista de mensagens definida.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5: Invocar o modelo e obter a resposta (com verificação)\n",
        "\n",
        "res = None # Inicializa a variável de resultado\n",
        "\n",
        "if chat: # Verifica se o modelo foi instanciado com sucesso\n",
        "    try:\n",
        "        print(f\"\\nEnviando mensagens para o modelo {chat.model}...\")\n",
        "        res = chat.invoke(messages)\n",
        "        print(\"Resposta recebida do modelo.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro durante a invocação do modelo: {e}\", file=sys.stderr)\n",
        "else:\n",
        "    print(\"\\nInvocação pulada pois o modelo não foi instanciado corretamente (verifique a API Key e a Célula 3).\", file=sys.stderr)\n",
        "\n",
        "# Exibe o objeto de resposta completo (opcional, útil para debug)\n",
        "# print(\"\\nObjeto de resposta completo:\")\n",
        "# print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sT-kwz8Nnwv",
        "outputId": "646fd304-dc76-4346-b9ca-cfb2a5c17559"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enviando mensagens para o modelo models/gemini-1.5-pro-latest...\n",
            "Resposta recebida do modelo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6: Imprimir o conteúdo da resposta (com verificação)\n",
        "\n",
        "if res: # Verifica se houve uma resposta válida\n",
        "    print(\"\\n--- Conteúdo da Resposta ---\")\n",
        "    print(res.content)\n",
        "    print(\"--------------------------\")\n",
        "elif chat: # Se o chat foi instanciado mas res é None, houve erro na invocação\n",
        "     print(\"\\nNão foi possível obter uma resposta do modelo (verifique o erro na Célula 5).\", file=sys.stderr)\n",
        "else:\n",
        "     print(\"\\nNão há resposta para exibir pois o modelo não foi instanciado.\", file=sys.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rXuQw_fSww3",
        "outputId": "15d69a7a-f81f-4732-bea9-126381240f1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Conteúdo da Resposta ---\n",
            "Machine Learning (Aprendizado de Máquina) é um subcampo da Inteligência Artificial (IA) que se concentra no desenvolvimento de sistemas que podem aprender com os dados sem serem explicitamente programados. Em vez de depender de regras predefinidas, os algoritmos de Machine Learning identificam padrões nos dados, fazem previsões e tomam decisões com base nesses padrões.  A precisão e a eficácia desses sistemas melhoram à medida que mais dados são processados.\n",
            "\n",
            "Aqui está uma analogia: imagine ensinar um cachorro um novo truque. Em vez de dar instruções passo a passo, você mostra exemplos, recompensa o comportamento correto e corrige o incorreto. Com o tempo, o cachorro aprende a associar suas ações às suas recompensas e punições, eventualmente dominando o truque. O Machine Learning funciona de maneira semelhante: o algoritmo é \"treinado\" com dados e \"aprende\" a realizar uma tarefa específica sem instruções explícitas.\n",
            "\n",
            "Existem três principais tipos de Machine Learning:\n",
            "\n",
            "* **Aprendizado Supervisionado:** O algoritmo é treinado com dados rotulados, ou seja, dados que já contêm a resposta correta.  O objetivo é aprender a mapear as entradas para as saídas corretas. Exemplos incluem classificação de imagens (ex: gato vs. cachorro) e previsão de preços de imóveis.\n",
            "\n",
            "* **Aprendizado Não Supervisionado:** O algoritmo é treinado com dados não rotulados e deve encontrar padrões e estruturas nos dados por conta própria. Exemplos incluem agrupamento de clientes com base em seus hábitos de compra e redução de dimensionalidade para visualização de dados.\n",
            "\n",
            "* **Aprendizado por Reforço:** O algoritmo aprende por meio de tentativa e erro, interagindo com um ambiente. Ele recebe recompensas por ações corretas e penalidades por ações incorretas, aprendendo a maximizar as recompensas ao longo do tempo. Exemplos incluem jogos (ex: AlphaGo) e robótica.\n",
            "\n",
            "**Em resumo, Machine Learning permite que os computadores:**\n",
            "\n",
            "* **Automatizem tarefas:** Realizam tarefas repetitivas e complexas com eficiência.\n",
            "* **Identifiquem padrões:** Encontram insights ocultos em grandes conjuntos de dados.\n",
            "* **Façam previsões:** Preveem resultados futuros com base em dados históricos.\n",
            "* **Se adaptem a novas informações:** Aprimoram seu desempenho à medida que mais dados se tornam disponíveis.\n",
            "\n",
            "**Exemplos de aplicações de Machine Learning no dia a dia:**\n",
            "\n",
            "* **Recomendações de produtos:** Sites de e-commerce e streaming.\n",
            "* **Filtros de spam:** Nos seus emails.\n",
            "* **Assistentes virtuais:** Como Siri e Alexa.\n",
            "* **Detecção de fraudes:** Em cartões de crédito.\n",
            "* **Diagnóstico médico:** Análise de imagens médicas.\n",
            "* **Carros autônomos:** Navegação e tomada de decisões.\n",
            "\n",
            "\n",
            "Espero que isso tenha ajudado a esclarecer o que é Machine Learning.  Se tiver mais perguntas, fique à vontade para perguntar!\n",
            "--------------------------\n"
          ]
        }
      ]
    }
  ]
}